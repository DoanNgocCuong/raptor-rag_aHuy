{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9965832,"sourceType":"datasetVersion","datasetId":6130545}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fastcoref","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T16:54:30.491474Z","iopub.execute_input":"2024-12-04T16:54:30.492090Z","iopub.status.idle":"2024-12-04T16:54:46.482301Z","shell.execute_reply.started":"2024-12-04T16:54:30.492046Z","shell.execute_reply":"2024-12-04T16:54:46.481436Z"}},"outputs":[{"name":"stdout","text":"Collecting fastcoref\n  Downloading fastcoref-2.1.6.tar.gz (27 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (4.66.4)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (1.26.4)\nRequirement already satisfied: scipy>=1.7.3 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (1.14.1)\nRequirement already satisfied: spacy>=3.0.6 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (3.8.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (2.4.0)\nRequirement already satisfied: transformers>=4.11.3 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (4.46.3)\nRequirement already satisfied: datasets>=2.5.2 in /opt/conda/lib/python3.10/site-packages (from fastcoref) (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (2.32.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.5.2->fastcoref) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (0.26.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.5.2->fastcoref) (6.0.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (8.3.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (0.12.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (2.10.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (3.1.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (70.0.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy>=3.0.6->fastcoref) (3.4.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->fastcoref) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->fastcoref) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->fastcoref) (3.3)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.11.3->fastcoref) (2024.5.15)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.11.3->fastcoref) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.11.3->fastcoref) (0.4.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->fastcoref) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->fastcoref) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->fastcoref) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->fastcoref) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->fastcoref) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.5.2->fastcoref) (4.0.3)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.0.6->fastcoref) (1.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets>=2.5.2->fastcoref) (3.1.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.6->fastcoref) (2.27.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.5.2->fastcoref) (2024.6.2)\nRequirement already satisfied: blis<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy>=3.0.6->fastcoref) (1.0.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy>=3.0.6->fastcoref) (0.1.4)\nCollecting numpy>=1.21.6 (from fastcoref)\n  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.6->fastcoref) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.0.6->fastcoref) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy>=3.0.6->fastcoref) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.5.2->fastcoref) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->fastcoref) (1.3.0)\nRequirement already satisfied: marisa-trie>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.0.6->fastcoref) (1.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.5.2->fastcoref) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.0.6->fastcoref) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.0.6->fastcoref) (0.1.2)\nDownloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fastcoref\n  Building wheel for fastcoref (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fastcoref: filename=fastcoref-2.1.6-py3-none-any.whl size=31253 sha256=f78379fa45dfb914c870e742c061c5ca9add83518aa03c2ec80d4328d99c55ba\n  Stored in directory: /root/.cache/pip/wheels/73/ac/49/24d3e434b85513f46503fbea7e7eb6353e32b66619ea86b410\nSuccessfully built fastcoref\nInstalling collected packages: numpy, fastcoref\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.10.1 requires cubinlinker, which is not installed.\ncudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.10.1 requires libcudf==24.10.*, which is not installed.\ncudf 24.10.1 requires ptxcompiler, which is not installed.\ncuml 24.10.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 24.10.0 requires cuvs==24.10.*, which is not installed.\ncuml 24.10.0 requires nvidia-cublas, which is not installed.\ncuml 24.10.0 requires nvidia-cufft, which is not installed.\ncuml 24.10.0 requires nvidia-curand, which is not installed.\ncuml 24.10.0 requires nvidia-cusolver, which is not installed.\ncuml 24.10.0 requires nvidia-cusparse, which is not installed.\ndask-cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\npylibcudf 24.10.1 requires libcudf==24.10.*, which is not installed.\npylibraft 24.10.0 requires nvidia-cublas, which is not installed.\npylibraft 24.10.0 requires nvidia-curand, which is not installed.\npylibraft 24.10.0 requires nvidia-cusolver, which is not installed.\npylibraft 24.10.0 requires nvidia-cusparse, which is not installed.\nucxx 0.40.0 requires libucxx==0.40.*, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 2.0.2 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\ncatboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.0.2 which is incompatible.\ncudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\ncudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ndask-cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\nibis-framework 7.1.0 requires numpy<2,>=1, but you have numpy 2.0.2 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmatplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 2.0.2 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\npylibcudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\nrmm 24.10.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\ntensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.2 which is incompatible.\ntensorflow-transform 0.14.0 requires numpy<2,>=1.16, but you have numpy 2.0.2 which is incompatible.\nxarray 2024.11.0 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fastcoref-2.1.6 numpy-2.0.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# from fastcoref import FCoref\n\n# # Khởi tạo mô hình\n# model = FCoref(device='cuda:0')  # Chọn GPU nếu có, nếu không thì để 'cpu'\n\n# # Văn bản đầu vào\n# texts = [\n#     \"Alice goes down the rabbit hole. She finds a strange world.\",\n#     \"Bob loves programming. He codes every day.\"\n# ]\n\n# # Dự đoán\n# preds = model.predict(texts=texts)\n\n# # Lấy các cụm từ có liên quan (clusters)\n# for i, pred in enumerate(preds):\n#     print(f\"Text {i + 1}:\")\n#     print(\"Clusters:\", pred.get_clusters())\n#     print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T16:54:46.484313Z","iopub.execute_input":"2024-12-04T16:54:46.484994Z","iopub.status.idle":"2024-12-04T16:55:16.349428Z","shell.execute_reply.started":"2024-12-04T16:54:46.484952Z","shell.execute_reply":"2024-12-04T16:55:16.348529Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9dfa45ea4434c799a6f2f8affa631f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/393 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06a584756aeb451bb786fd8a3b5fa828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e706cb500234d5ca5c9a095bda901e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c970f26deb0f4d8084b1e628f7910bfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0107cfcd26f145ef95609c894026723e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70e9d66e2d6f423c91957ea009cc3255"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/362M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"981bd69dd110476ab9b5c3ad86cd0625"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a0ebf0ea724022aeb5d7da3f17bbf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Inference:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"387a4233511d4eacb243a6076aead855"}},"metadata":{}},{"name":"stdout","text":"Text 1:\nClusters: []\n\nText 2:\nClusters: [['Bob', 'He']]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Tích hợp với SpaCy\nBạn có thể tích hợp fastcoref như một pipeline trong SpaCy:","metadata":{}},{"cell_type":"code","source":"from fastcoref import spacy_component\nimport spacy\n\n# Tải SpaCy và thêm pipeline `fastcoref`\nnlp = spacy.load(\"en_core_web_sm\")\nnlp.add_pipe(\"fastcoref\")\n\n# Dự đoán với văn bản\ndoc = nlp(\"Alice goes down the rabbit hole. She finds a strange world. Bob loves programming. He codes every day.\")\nprint(doc._.coref_clusters)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:23:50.011334Z","iopub.execute_input":"2024-12-04T17:23:50.011892Z","iopub.status.idle":"2024-12-04T17:23:52.177187Z","shell.execute_reply.started":"2024-12-04T17:23:50.011857Z","shell.execute_reply":"2024-12-04T17:23:52.176131Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10a4b3b6482434589d9d6680441451e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Inference:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"944d148e88834bcdae95f7081e6d5ca8"}},"metadata":{}},{"name":"stdout","text":"[[(0, 5), (33, 36)], [(60, 63), (83, 85)]]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Hiển thị các cụm từ tham chiếu\nfor cluster in doc._.coref_clusters:\n    resolved_text = [doc.text[start:end] for start, end in cluster]\n    print(\"Cluster:\", resolved_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:23:54.451403Z","iopub.execute_input":"2024-12-04T17:23:54.451761Z","iopub.status.idle":"2024-12-04T17:23:54.456914Z","shell.execute_reply.started":"2024-12-04T17:23:54.451726Z","shell.execute_reply":"2024-12-04T17:23:54.456053Z"}},"outputs":[{"name":"stdout","text":"Cluster: ['Alice', 'She']\nCluster: ['Bob', 'He']\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Văn bản gốc\ntext = \"Alice goes down the rabbit hole. She finds a strange world. Bob loves programming. He codes every day.\"\n\n# Dự đoán với văn bản\ndoc = nlp(text)\n\n# Hiển thị các cụm từ tham chiếu\nfor cluster in doc._.coref_clusters:\n    resolved_mentions = [text[start:end] for start, end in cluster]\n    print(\"Cluster:\", resolved_mentions)\n\n# Chuyển văn bản thành danh sách ký tự để tránh lỗi chỉ số\ntokens = list(text)\n\n# Thay thế đại từ nhân xưng bằng thực thể chính\nfor cluster in doc._.coref_clusters:\n    main_mention = text[cluster[0][0]:cluster[0][1]]  # Cụm chính\n    for start, end in cluster[1:]:  # Các cụm còn lại\n        pronoun = text[start:end]\n        # Chỉ thay thế nếu là đại từ nhân xưng\n        if pronoun.lower() in [\"he\", \"she\", \"him\", \"her\", \"his\", \"hers\", \"they\", \"them\", \"their\"]:\n            # Thay thế trực tiếp trên danh sách ký tự\n            tokens[start:end] = list(main_mention)\n\n# Ghép danh sách ký tự thành chuỗi hoàn chỉnh\nresolved_text = ''.join(tokens)\n\nprint(\"\\nOriginal Text:\")\nprint(text)\nprint(\"\\nResolved Text (Pronouns Replaced):\")\nprint(resolved_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:30:00.618584Z","iopub.execute_input":"2024-12-04T17:30:00.619121Z","iopub.status.idle":"2024-12-04T17:30:00.896067Z","shell.execute_reply.started":"2024-12-04T17:30:00.619084Z","shell.execute_reply":"2024-12-04T17:30:00.895205Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44e4f968ae3a4edf8c27e1991a397c40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Inference:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e78c781e3d334bc1a8fc1bfffc05c228"}},"metadata":{}},{"name":"stdout","text":"Cluster: ['Alice', 'She']\nCluster: ['Bob', 'He']\n\nOriginal Text:\nAlice goes down the rabbit hole. She finds a strange world. Bob loves programming. He codes every day.\n\nResolved Text (Pronouns Replaced):\nAlice goes down the rabbit hole. Alice finds a strange world. Bob loves programmingBobHe codes every day.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"### **Hướng dẫn và giải thích repo `fastcoref`**\r\n\r\n`fastcoref` là một thư viện Python mạnh mẽ để thực hiện nhiệm vụ \"Coreference Resolution\" - xác định các cụm từ hoặc từ nào trong văn bản tham chiếu đến cùng một thực thể.\r\n\r\nDưới đây là từng bước giải thích nội dung của repository này và hướng dẫn cài đặt và sử dụng:\r\n\r\n---\r\n\r\n### **1. Cài đặt**\r\n\r\nBạn cần cài đặt thư viện này thông qua `pip`:\r\n\r\n```bash\r\npip install fastcoref\r\n```\r\n\r\nNếu bạn muốn huấn luyện mô hình riêng, hãy cài đặt thêm các phụ thuộc huấn luyện:\r\n\r\n```bash\r\npip install fastcoref[train]\r\n```\r\n\r\n---\r\n\r\n### **2. Chức năng chính: Coreference Resolution**\r\n\r\nCoreference Resolution là nhiệm vụ xác định các từ hoặc cụm từ nào trong văn bản tham chiếu đến cùng một thực thể. Ví dụ:\r\n\r\n- Văn bản: `\"Alice goes down the rabbit hole. She finds a strange world.\"`\r\n- Kết quả: `\"She\"` tham chiếu đến `\"Alice\"`.\r\n\r\n---\r\n\r\n### **3. Sử dụng cơ bản**\r\n\r\nDưới đây là cách sử dụng `fastcoref` để thực hiện coreference resolution:\r\n\r\n#### **Code cơ bản**\r\n```python\r\nfrom fastcoref import FCoref\r\n\r\n# Khởi tạo mô hình\r\nmodel = FCoref(device='cuda:0')  # Chọn GPU nếu có, nếu không thì để 'cpu'\r\n\r\n# Văn bản đầu vào\r\ntexts = [\r\n    \"Alice goes down the rabbit hole. She finds a strange world.\",\r\n    \"Bob loves programming. He codes every day.\"\r\n]\r\n\r\n# Dự đoán\r\npreds = model.predict(texts=texts)\r\n\r\n# Lấy các cụm từ có liên quan (clusters)\r\nfor i, pred in enumerate(preds):\r\n    print(f\"Text {i + 1}:\")\r\n    print(\"Clusters:\", pred.get_clusters())\r\n    print()\r\n```\r\n\r\n#### **Kết quả**\r\n```plaintext\r\nText 1:\r\nClusters: [['Alice', 'She']]\r\n\r\nText 2:\r\nClusters: [['Bob', 'He']]\r\n```\r\n\r\n---\r\n\r\n### **4. Giải thích từng thành phần**\r\n\r\n#### **`model.predict`**\r\n- Nhận danh sách các văn bản.\r\n- Trả về danh sách `CorefResult` cho từng văn bản.\r\n\r\n#### **Các phương thức trong `CorefResult`**\r\n1. **`get_clusters()`**:\r\n   - Trả về danh sách các cụm từ tham chiếu đến cùng thực thể.\r\n\r\n2. **`get_clusters(as_strings=False)`**:\r\n   - Trả về danh sách các chỉ số (start, end) của cụm từ trong văn bản gốc.\r\n\r\n3. **`get_logit(span_i, span_j)`**:\r\n   - Trả về điểm xác suất rằng hai cụm từ `span_i` và `span_j` tham chiếu đến cùng thực thể.\r\n\r\n---\r\n\r\n### **5. Sử dụng với văn bản đã tokenized**\r\n\r\nNếu văn bản đã được tokenized (chia từ sẵn), bạn có thể đặt `is_split_into_words=True`:\r\n\r\n#### **Code**\r\n```python\r\npreds = model.predict(\r\n    texts=[[\"Alice\", \"goes\", \"down\", \"the\", \"rabbit\", \"hole\", \".\", \"She\", \"finds\", \"a\", \"strange\", \"world\", \".\"]],\r\n    is_split_into_words=True\r\n)\r\nprint(preds[0].get_clusters())\r\n```\r\n\r\n#### **Kết quả**\r\n```plaintext\r\n[['Alice', 'She']]\r\n```\r\n\r\n---\r\n\r\n### **6. Tăng tốc với xử lý hàng loạt**\r\n\r\nĐể xử lý nhiều văn bản cùng lúc và tối ưu hóa tài nguyên, bạn có thể sử dụng tham số `max_tokens_in_batch`:\r\n\r\n#### **Code**\r\n```python\r\ntexts = [\"Alice goes to school.\", \"Bob plays soccer.\"] * 1000\r\n\r\n# Sử dụng batch processing\r\npreds = model.predict(texts=texts, max_tokens_in_batch=100)\r\n```\r\n\r\n---\r\n\r\n### **7. Tích hợp với SpaCy**\r\n\r\nBạn có thể tích hợp `fastcoref` như một pipeline trong SpaCy:\r\n\r\n#### **Code**\r\n```python\r\nfrom fastcoref import spacy_component\r\nimport spacy\r\n\r\n# Tải SpaCy và thêm pipeline `fastcoref`\r\nnlp = spacy.load(\"en_core_web_sm\")\r\nnlp.add_pipe(\"fastcoref\")\r\n\r\n# Dự đoán với văn bản\r\ndoc = nlp(\"Alice goes down the rabbit hole. She finds a strange world.\")\r\nprint(doc._.coref_clusters)\r\n```\r\n\r\n#### **Kết quả**\r\n```plaintext\r\n[[('Alice', 0, 5), ('She', 27, 30)]]\r\n```\r\n\r\n---\r\n\r\n### **8. Huấn luyện mô hình riêng**\r\n\r\nNếu bạn muốn huấn luyện mô hình riêng, thư viện hỗ trợ:\r\n\r\n1. **Chuẩn bị dữ liệu:**\r\n   - Dữ liệu cần có định dạng `jsonlines`, với thông tin cụm từ (clusters).\r\n\r\n2. **Sử dụng `CorefTrainer` để huấn luyện:**\r\n   ```python\r\n   from fastcoref import TrainingArgs, CorefTrainer\r\n\r\n   args = TrainingArgs(\r\n       output_dir='my_model',\r\n       model_name_or_path='distilroberta-base',\r\n       device='cuda:0',\r\n       epochs=10\r\n   )\r\n\r\n   trainer = CorefTrainer(\r\n       args=args,\r\n       train_file='train_data.jsonlines',\r\n       dev_file='dev_data.jsonlines'\r\n   )\r\n   trainer.train()\r\n   ```\r\n\r\n3. **Tải mô hình đã huấn luyện:**\r\n   ```python\r\n   from fastcoref import FCoref\r\n   model = FCoref(model_name_or_path='my_model', device='cuda:0')\r\n   ```\r\n\r\n---\r\n\r\n### **Tóm tắt**\r\n\r\n- **Cài đặt:** `pip install fastcoref`\r\n- **Dự đoán:** `model.predict()`\r\n- **Tích hợp SpaCy:** `nlp.add_pipe(\"fastcoref\")`\r\n- **Huấn luyện mô hình riêng:** Sử dụng `CorefTrainer`.\r\n\r\nNếu bạn cần hỗ trợ thêm, hãy cho biết chi tiết!","metadata":{}},{"cell_type":"markdown","source":"### **Giải thích kết quả `doc._.coref_clusters`**\r\n\r\nKhi bạn chạy đoạn mã:\r\n\r\n```python\r\nfrom fastcoref import spacy_component\r\nimport spacy\r\n\r\n# Tải SpaCy và thêm pipeline `fastcoref`\r\nnlp = spacy.load(\"en_core_web_sm\")\r\nnlp.add_pipe(\"fastcoref\")\r\n\r\n# Dự đoán với văn bản\r\ndoc = nlp(\"Alice goes down the rabbit hole. She finds a strange world. Bob loves programming. He codes every day.\")\r\nprint(doc._.coref_clusters)\r\n```\r\n\r\n#### **Kết quả:**\r\n```plaintext\r\n[[(0, 5), (33, 36)], [(60, 63), (83, 85)]]\r\n```\r\n\r\n---\r\n\r\n### **Giải thích từng phần**\r\n\r\n1. **Kết quả dạng danh sách các cụm (clusters):**\r\n\r\n   - `doc._.coref_clusters` trả về danh sách các cụm từ mà mô hình nhận diện là tham chiếu đến cùng một thực thể.\r\n\r\n2. **Cấu trúc kết quả:**\r\n   ```python\r\n   [[(0, 5), (33, 36)], [(60, 63), (83, 85)]]\r\n   ```\r\n   - Mỗi cụm (cluster) là một danh sách các cặp `(start, end)`:\r\n     - `(start, end)` đại diện cho vị trí ký tự bắt đầu và kết thúc của một cụm từ trong văn bản gốc.\r\n\r\n---\r\n\r\n### **Ví dụ chi tiết với văn bản:**\r\n\r\n```plaintext\r\nAlice goes down the rabbit hole. She finds a strange world. \r\nBob loves programming. He codes every day.\r\n```\r\n\r\n#### **Kết quả phân tích cụm:**\r\n1. **Cụm đầu tiên: `[(0, 5), (33, 36)]`**\r\n   - `(0, 5)` → `\"Alice\"` (từ ký tự 0 đến 5 trong văn bản).\r\n   - `(33, 36)` → `\"She\"` (từ ký tự 33 đến 36 trong văn bản).\r\n   - **Kết quả:** `\"Alice\"` và `\"She\"` tham chiếu đến cùng một thực thể.\r\n\r\n2. **Cụm thứ hai: `[(60, 63), (83, 85)]`**\r\n   - `(60, 63)` → `\"Bob\"` (từ ký tự 60 đến 63 trong văn bản).\r\n   - `(83, 85)` → `\"He\"` (từ ký tự 83 đến 85 trong văn bản).\r\n   - **Kết quả:** `\"Bob\"` và `\"He\"` tham chiếu đến cùng một thực thể.\r\n\r\n---\r\n\r\n### **Hướng dẫn thêm để trực quan hóa:**\r\n\r\nBạn có thể sử dụng Python để truy xuất trực tiếp các từ hoặc cụm từ từ văn bản:\r\n\r\n```python\r\n# Hiển thị các cụm từ tham chiếu\r\nfor cluster in doc._.coref_clusters:\r\n    resolved_text = [doc.text[start:end] for start, end in cluster]\r\n    print(\"Cluster:\", resolved_text)\r\n```\r\n\r\n#### **Kết quả:**\r\n```plaintext\r\nCluster: ['Alice', 'She']\r\nCluster: ['Bob', 'He']\r\n```\r\n\r\n---\r\n\r\n### **Tóm tắt:**\r\n- **`doc._.coref_clusters`** trả về danh sách các cụm tham chiếu trong văn bản.\r\n- **Mỗi cụm** gồm các cặp `(start, end)` biểu diễn vị trí trong văn bản gốc.\r\n- **Cách sử dụng:** Có thể dùng các chỉ số `(start, end)` để trích xuất các cụm từ gốc hoặc dùng trực tiếp cho các ứng dụng NLP.","metadata":{}},{"cell_type":"markdown","source":"## Load Dataset \n","metadata":{}},{"cell_type":"code","source":"import json\n\n# Đường dẫn tới file JSON\nfile_path = '/kaggle/input/rag-dataset/data/corpus/raw/hotpotqa.json'\n\n\nwith open(file_path, 'r', encoding='utf-8') as file:\n    data = json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:00:25.921283Z","iopub.execute_input":"2024-12-04T17:00:25.922090Z","iopub.status.idle":"2024-12-04T17:00:26.279314Z","shell.execute_reply.started":"2024-12-04T17:00:25.922051Z","shell.execute_reply":"2024-12-04T17:00:26.278385Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"data[0]['paragraph_text']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:03:42.772523Z","iopub.execute_input":"2024-12-04T17:03:42.773135Z","iopub.status.idle":"2024-12-04T17:03:42.778708Z","shell.execute_reply.started":"2024-12-04T17:03:42.773102Z","shell.execute_reply":"2024-12-04T17:03:42.777718Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'Passage 1:\\nTrusty system (prison)\\nThe \"trusty system\" (sometimes incorrectly called \"trustee system\") was a penitentiary system of discipline and security enforced in parts of the United States until the 1980s, in which designated inmates were given various privileges, abilities, and responsibilities not available to all inmates.It was made compulsory under Mississippi state law but was used in other states as well, such as Arkansas, Alabama, Louisiana, New York and Texas. The method of controlling and working inmates at Mississippi State Penitentiary at Parchman was designed in 1901 to replace convict leasing. The case Gates v. Collier ended the flagrant abuse of inmates under the trusty system and other prison abuses that had continued essentially unchanged since the building of the Mississippi State Penitentiary. Other states using the trusty system were also forced to give it up under the ruling.\\n\\nHistory\\nPrisons had trusties as far back as the 1800s.\\n\\nParchman Farm\\nThe prison had approximately 16,000 acres (65 km2) of farmland and grew such cash crops as cotton as well as engaged in livestock production. Although the population of the prison was around 1,900 inmates (two thirds of whom were black and in racially-segregated units), the law allowed only a maximum of 150 staff members to be hired to minimize operating costs. Thus, the farm labor was done by inmates.The bulk of guarding and disciplining of the inmates was performed by inmate trusties. They also performed most of the administrative work, supervised by a few employees. Therefore, the inmate trusties essentially controlled inmate care and custody, basically running the prison system.Highest in the prison inmate hierarchy were the inmates armed with rifles, called the \"trusty shooters\". Their job was to act as prison guards and control other inmates on a day-to-day basis in the residential camps or out on the field work crews. Next came the unarmed trusties who performed janitorial, clerical, and other menial tasks for the prison\\'s staff. Simple tasks, such as distributing medication, were carried out by other categories of inmates such as \"hallboys\". Inmate trusties enforced discipline within the prison inmate living quarters (16 different residential camps) and in the work camps and prison farms. In addition to punishment administered on site, inmate trusties could recommend further punishment in the special punishment area for disobedient or disruptive inmates.According to attorney Roy Haber, who handled the series of litigation cases brought by the American Civil Liberties Union against the trusty system, inmates were whipped with leather straps for failing to pick their daily quota of cotton. The farm\\'s camps of black inmates were supervised by one white sergeant, and under him the black inmate \"trusty shooters\", who were serving sentences for murder, carried rifles and enforced discipline.\\n\\nAbolition\\nGates v. Collier (Gates v. Collier Prison Reform Case, 1970–1971) ended the flagrant abuse of inmates under the trusty system and other prison abuses that had continued essentially unchanged since the building of the prison in 1903. On October 20, 1972, Federal Judge William Keady ordered the end of racial segregation in prison residential quarters. He also required replacement of trusty shooters with civilian prison guards.Any system in which inmates were allowed to be in a position of authority and control other inmates or to use physical abuse or intimidation of other inmates was abolished. It also found some types of corporal punishment were a violation of an inmate\\'s Eighth Amendment rights, including \"handcuffing inmates to the fence and to cells for, long periods of time,... and forcing inmates to stand, sit or lie on crates, stumps, or otherwise maintain awkward positions for prolonged periods.\"Its structure and abuses were detailed in Hope v. Pelzer in which a former inmate sued the prison superintendent for personal injury suffered under the trusty system.Other states using the trusty system, such as Arkansas, Alabama, Louisiana, and Texas were also forced to abolish it under the Gates v. Collier rulings. However, some states, such as Texas, still continued their use of trusty systems (known as \"building tenders\") until the 1980s, when Federal Judge William Wayne Justice, in Ruiz v. Estelle, 503 F. Supp. 1265 (S.D. Tex. 1980), compelled the replacement of the trusty system with the strictly-regulated Support Service Inmate (SSI) system.\\n\\nSee also\\n\"Parchman Farm\" (song)\\nLouisiana State Penitentiary\\nKapo\\n'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# from fastcoref import spacy_component\n# import spacy\n\n# # Tải SpaCy và thêm pipeline `fastcoref`\n# nlp = spacy.load(\"en_core_web_sm\")\n# nlp.add_pipe(\"fastcoref\")\n\n# Dự đoán với văn bản\ntext = data[0]['paragraph_text']\ndoc = nlp(text)\nprint(doc._.coref_clusters)\n\n\n# Hiển thị các cụm từ tham chiếu\nfor cluster in doc._.coref_clusters:\n    resolved_text = [doc.text[start:end] for start, end in cluster]\n    print(\"Cluster:\", resolved_text)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T17:04:08.977071Z","iopub.execute_input":"2024-12-04T17:04:08.977411Z","iopub.status.idle":"2024-12-04T17:04:09.498321Z","shell.execute_reply.started":"2024-12-04T17:04:08.977379Z","shell.execute_reply":"2024-12-04T17:04:09.497296Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9cabf2dea374a628844c2b410d9e927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Inference:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daa86504a25046a2be6a5672430b1361"}},"metadata":{}},{"name":"stdout","text":"[[(34, 101), (331, 333), (687, 704), (847, 864), (890, 892), (2601, 2618), (3031, 3048), (3987, 4004), (4024, 4041), (4119, 4121), (4413, 4430)], [(527, 569), (792, 826), (985, 995), (1154, 1164), (2018, 2030), (3136, 3146)], [(1460, 1475), (1477, 1481), (1572, 1591)], [(1720, 1779), (1781, 1786)], [(2620, 2627), (2681, 2686)], [(2763, 2781), (2793, 2796)], [(3177, 3204), (3275, 3277)], [(2923, 2988), (3524, 3526), (4132, 4148)], [(428, 436), (4051, 4059)], [(438, 445), (4061, 4068)], [(447, 456), (4070, 4079)], [(471, 476), (4085, 4090), (4188, 4193)], [(4167, 4194), (4211, 4216)], [(200, 209), (4275, 4284)]]\nCluster: ['The \"trusty system\" (sometimes incorrectly called \"trustee system\")', 'It', 'the trusty system', 'the trusty system', 'it', 'the trusty system', 'the trusty system', 'the trusty system', 'the trusty system', 'it', 'the trusty system']\nCluster: ['Mississippi State Penitentiary at Parchman', 'the Mississippi State Penitentiary', 'The prison', 'the prison', \"the prison's\", 'the prison']\nCluster: ['inmate trusties', 'They', 'the inmate trusties']\nCluster: ['the inmates armed with rifles, called the \"trusty shooters\"', 'Their']\nCluster: ['inmates', 'their']\nCluster: ['one white sergeant', 'him']\nCluster: ['Federal Judge William Keady', 'He']\nCluster: ['Gates v. Collier (Gates v. Collier Prison Reform Case, 1970–1971)', 'It', 'Gates v. Collier']\nCluster: ['Arkansas', 'Arkansas']\nCluster: ['Alabama', 'Alabama']\nCluster: ['Louisiana', 'Louisiana']\nCluster: ['Texas', 'Texas', 'Texas']\nCluster: ['some states, such as Texas,', 'their']\nCluster: ['the 1980s', 'the 1980s']\n","output_type":"stream"}],"execution_count":17}]}