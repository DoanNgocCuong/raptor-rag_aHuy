{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from sentence_transformers.models import StaticEmbedding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_embedding = StaticEmbedding.from_distillation(\"BAAI/bge-m3\")\n",
    "model = SentenceTransformer(\n",
    "    modules=[static_embedding],\n",
    "    device=\"cuda\",\n",
    "    trust_remote_code=True,\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "    },\n",
    ")\n",
    "\n",
    "# model = SentenceTransformer(\n",
    "#     \"BAAI/bge-m3\",\n",
    "#     device=\"cuda\",\n",
    "#     trust_remote_code=True,\n",
    "#     model_kwargs={\n",
    "#         \"torch_dtype\": torch.float16,\n",
    "#     },\n",
    "# )\n",
    "\n",
    "reranker = CrossEncoder(\n",
    "    \"BAAI/bge-reranker-v2-m3\",\n",
    "    device=\"cuda\",\n",
    "    trust_remote_code=True,\n",
    "    automodel_args={\n",
    "        \"torch_dtype\": torch.float16,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pl.read_csv(\"../data/corpus.csv\")\n",
    "public_test = pl.read_csv(\"../data/public_test.csv\")\n",
    "corpus_text = corpus[\"text\"].to_list()\n",
    "corpus_id = corpus[\"cid\"].to_list()\n",
    "questions = public_test[\"question\"].to_list()\n",
    "question_id = public_test[\"qid\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embedding Corpus and Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_embeddings = model.encode(\n",
    "    corpus_text,\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_question_embeddings = model.encode(\n",
    "    questions,\n",
    "    batch_size=16,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Retrieve top k Corpus (Baseline) For each Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = model.similarity(public_question_embeddings, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = torch.topk(similarities,8, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_top_k = top_k.indices.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Retrieve top k Corpus (BM25) For each Question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = bm25s.BM25(corpus=corpus_text)\n",
    "retriever.index(bm25s.tokenize(corpus_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_top_k = []\n",
    "for question in tqdm(questions, total=len(questions)):\n",
    "    results, scores = retriever.retrieve(\n",
    "        bm25s.tokenize(question),\n",
    "        k=8,\n",
    "    )\n",
    "    top_id = list(map(lambda x: corpus_text.index(x), results.tolist()[0]))\n",
    "    bm25_top_k.append(top_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = list(set(bge_top_k[1] + bm25_top_k[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_top_k = list(map(lambda a: list(set(a[0] + a[1])), zip(bge_top_k, bm25_top_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rerank to 10 corpus/question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_rerank(query, corpus, top_k_indices):\n",
    "    rerank_score = reranker.rank(\n",
    "        query=query,\n",
    "        batch_size=4,\n",
    "        documents=[corpus[\"text\"][idx] for idx in top_k_indices],\n",
    "    )\n",
    "    top_k_id = list(map(lambda x: x[\"corpus_id\"], rerank_score[:10]))\n",
    "    final_top_k = [top_k_indices[i] for i in top_k_id]\n",
    "    return final_top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_index = []\n",
    "for i in tqdm(range(len(public_test)), total=len(public_test)):\n",
    "    rerank_index.append(\n",
    "        final_rerank(public_test[\"question\"][i], corpus, merge_top_k[i])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_corpus_id = [\n",
    "    [corpus_id[idx] for idx in rerank_index[i]] for i in range(len(rerank_index))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rerank_corpus_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_id = public_test[\"qid\"]\n",
    "list_output = []\n",
    "for idx, index in zip(q_id, rerank_corpus_id):\n",
    "    list_output.append(f\"{idx} {' '.join(map(str, index))}\")\n",
    "\n",
    "# Save the output\n",
    "with open(\"bm25/predict.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(list_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "(\n",
    "    rerank_corpus_id[index],\n",
    "    [corpus_id[i] for i in bge_top_k[index]],\n",
    "    [corpus_id[i] for i in bm25_top_k[index]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
