{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwLN4DPjWwQr"
      },
      "source": [
        "### Testing Model: Model nào 1.5B ?? - Output nó như nào? Prompting như nào ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CG1-PlBruUD"
      },
      "source": [
        "```\n",
        "def answer_question(final_context, query, model=\"Qwen/Qwen2-1.5B-Instruct\", max_tokens=500, api_key=\"your_api_key_here\"):\n",
        "    \"\"\"\n",
        "    Generates an answer for the query using the Hugging Face Inference API with the specified model.\n",
        "\n",
        "    Args:\n",
        "        final_context (str): The context to provide for the query.\n",
        "        query (str): The user query.\n",
        "        model (str): The model to use for chat completion.\n",
        "        max_tokens (int): Maximum tokens for the output.\n",
        "        api_key (str): Hugging Face API key.\n",
        "\n",
        "    Returns:\n",
        "        str: The model's response to the query.\n",
        "    \"\"\"\n",
        "    client = InferenceClient(api_key=api_key)\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                f\"Answer the question based on the provided context.\\n\\n\"\n",
        "                f\"Context:\\n{final_context}\\n\\n\"\n",
        "                f\"Question: {query}\\n\\n\"\n",
        "                f\"Provide a short answer in less than 5 words, in the following JSON format:\\n\"\n",
        "                f'{{\"short_answer\": \"<short answer in less than 5 words>\"}}'\n",
        "            )\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    # Generate completion\n",
        "    completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=0  # Ensures consistent results\n",
        "    )\n",
        "    \n",
        "    # Extract and return the assistant's response\n",
        "    return completion.choices[0].message['content']\n",
        "```\n",
        "\n",
        "thay việc call API bằng việc sử dụng\n",
        "\n",
        "```\n",
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
        "pipe(messages)\n",
        "```\n",
        "\n",
        "Cho ổn định"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hla7j2VKaWO9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CgRcqSRpHDUk"
      },
      "outputs": [],
      "source": [
        "# if you want to use the Gemma, you will need to authenticate with HuggingFace, Skip this step, if you have the model already downloaded\n",
        "import huggingface_hub\n",
        "huggingface_hub.login('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')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mewy2i2bMiCZ",
        "outputId": "6570a27d-b913-4ec0-ed8a-199cd03a9199"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "\n",
        "# Model setup\n",
        "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"  # Replace with your actual model name\n",
        "model_name = \"meta-llama/Llama-3.2-1B\" # bị lỗi lặp từ trong response\n",
        "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "qa_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_name,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BWMBgC-rft-m"
      },
      "outputs": [],
      "source": [
        "# Function to retrieve relevant content from a single chunk\n",
        "def retrieval_chunk_text(query, chunk_text):\n",
        "    \"\"\"\n",
        "    Extracts relevant content from a single chunk based on the query.\n",
        "    \"\"\"\n",
        "    prompt = f\"Extract the most relevant information from the following passage based on the query.\\n\\nPassage: {chunk_text}\\n\\nQuery: {query}\\n Relevant Content:\"\n",
        "    outputs = qa_pipeline(prompt, max_new_tokens=128, do_sample=False)\n",
        "    relevant_text = outputs[0][\"generated_text\"].strip()\n",
        "    return relevant_text\n",
        "\n",
        "# Function to combine the top_k relevant chunks into a final context\n",
        "def combine_top_k_chunk_text(query, top_k_chunks, top_k=5):\n",
        "    \"\"\"\n",
        "    Combines the most relevant parts of the top_k chunks into one context.\n",
        "    \"\"\"\n",
        "    combined_context = []\n",
        "    for i in range(min(top_k, len(top_k_chunks))):\n",
        "        chunk_text = top_k_chunks[i]['text']  # Extract text from the chunk\n",
        "        relevant_text = retrieval_chunk_text(query, chunk_text)  # Retrieve relevant text\n",
        "        combined_context.append(relevant_text)\n",
        "    retrieval_final_context = \"\\n\".join(combined_context)\n",
        "    return retrieval_final_context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzDHGxz4fzO0",
        "outputId": "7fc0cdd1-1813-4345-d016-083355af344f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Example Usage\n",
        "query = \"Which case was brought to court first Miller v. California or Gates v. Collier \"\n",
        "top_k_chunks = [\n",
        "    {\"text\": \"Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of 'utterly without socially redeeming value' to that which lacks 'serious literary, artistic, political, or scientific value.'\"},\n",
        "    {\"text\": \"The case redefined obscenity to include only materials that lack serious literary, artistic, political, or scientific value, creating the 'Miller test' that is still used today.\"},\n",
        "    {\"text\": \"Miller appealed his conviction on the grounds that the jury had not been instructed to consider whether the material in question lacked serious value, which led to the new definition being adopted.\"},\n",
        "    {\"text\": \"Gates v. Collier, on the other hand, was a landmark decision by the Fifth Circuit Court of Appeals that brought an end to the 'trusty system' and cruel practices at Parchman Farm prison in Mississippi.\"},\n",
        "    {\"text\": \"The 'Miller test' consists of three prongs: whether the average person, applying contemporary community standards, would find the work appeals to the prurient interest; whether it depicts sexual conduct in a patently offensive way; and whether it lacks serious value.\"},\n",
        "    {\"text\": \"The significance of the Miller v. California decision lies in its establishment of a clearer standard for defining obscenity, which has been pivotal in subsequent First Amendment cases.\"},\n",
        "    {\"text\": \"In Miller v. California, the Supreme Court emphasized that works must be taken as a whole and judged by community standards to determine their appeal to prurient interests.\"},\n",
        "    {\"text\": \"The ruling in Miller v. California provided states with greater flexibility to enforce obscenity laws, leading to a resurgence of prosecutions in the years following the decision.\"},\n",
        "    {\"text\": \"Critics of the Miller v. California decision argue that its reliance on 'community standards' can lead to inconsistent applications of the law across different regions.\"},\n",
        "    {\"text\": \"Proponents of the decision maintain that it strikes a necessary balance between protecting free speech and allowing communities to regulate obscene materials that may harm societal values.\"}\n",
        "]\n",
        "\n",
        "# Step 1: Combine top_k chunk texts into a final context\n",
        "retrieval_final_context = combine_top_k_chunk_text(query, top_k_chunks, top_k=5)\n",
        "\n",
        "# # Step 2: Answer the query using the combined context\n",
        "# answer = answer_question(retrieval_final_context, query)\n",
        "\n",
        "# print(f\"Final Answer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "27xAqe7Ef0b8",
        "outputId": "50dc292c-f7fe-4a85-b0f9-1af451b5170a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Extract the most relevant information from the following passage based on the query.\\n\\nPassage: Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of \\'utterly without socially redeeming value\\' to that which lacks \\'serious literary, artistic, political, or scientific value.\\'\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\n\\nThe answer is: Miller v. California was brought to court first. \\n\\nExplanation: The passage states that \"Miller v. California, 413 U.S. 15 (1973)\" was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of \\'utterly without socially redeeming value\\' to that which lacks\\'serious literary, artistic, political, or scientific value.\\' This indicates that Miller v. California was the case that was brought to court first. The second part of the question asks about another case, but there is no mention of any\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: The case redefined obscenity to include only materials that lack serious literary, artistic, political, or scientific value, creating the \\'Miller test\\' that is still used today.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\nThe answer: Miller v. California\\n\\nExplanation: The passage states that the case that defined obscenity as only containing materials lacking serious literary, artistic, political, or scientific value created the \"Miller test\" which is still used today. This indicates that the case that brought this definition to court was Miller v. California. Therefore, the correct answer is Miller v. California. \\n\\nGates v. Collier is not mentioned in the passage and does not provide any relevant information about the case that brought the definition of obscenity to court. Hence, it cannot be considered as a valid answer.\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: Miller appealed his conviction on the grounds that the jury had not been instructed to consider whether the material in question lacked serious value, which led to the new definition being adopted.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\nThe answer is: Miller v. California\\n\\nExplanation: The passage mentions that Miller appealed his conviction on the grounds that the jury had not been instructed to consider whether the material in question lacked serious value, which led to the new definition being adopted. This indicates that Miller\\'s appeal was related to a case where the jury did not consider the lack of serious value as an important factor. Therefore, the case that was brought to court first is Miller v. California. \\n\\nGates v. Collier is not mentioned in the passage and does not provide any information about the relevance of the jury instruction in Miller\\'s case.\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: Gates v. Collier, on the other hand, was a landmark decision by the Fifth Circuit Court of Appeals that brought an end to the \\'trusty system\\' and cruel practices at Parchman Farm prison in Mississippi.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Gates v. Collier\\nThe answer is: Gates v. Collier\\n\\nThe passage states that \"Gates v. Collier\" was a landmark decision by the Fifth Circuit Court of Appeals that brought an end to the \\'trusty system\\' and cruel practices at Parchman Farm prison in Mississippi. Therefore, it can be inferred that \"Gates v. Collier\" was brought to court first. The question asks for which case was brought to court first, and the relevant content provided in the passage confirms this. \\n\\nMiller v. California is not mentioned in the passage as being related to the context of the Fifth Circuit Court\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: The \\'Miller test\\' consists of three prongs: whether the average person, applying contemporary community standards, would find the work appeals to the prurient interest; whether it depicts sexual conduct in a patently offensive way; and whether it lacks serious value.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\nThe Miller test is used to determine if material is obscene under state law.\\nGates v. Collier\\nThis case involved a challenge to a state obscenity statute.\\nAnswer:\\n\\nMiller v. California was brought to court first. \\n\\nExplanation:\\n- The question asks for the order in which cases were brought to court. \\n- The passage states that \"the Miller test is used to determine if material is obscene under state law.\" This implies that the Miller test was developed before any other similar tests like the one used in Gates v. Collier.\\n- Therefore, Miller v. California was brought to court first.'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_final_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUeoseFhaYIn"
      },
      "source": [
        "## Thay đổi 1 cách load model mới - đơn giản trong việc gọi model và đơn giản trong response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH9o1ldLXEev",
        "outputId": "cb06bb04-f48f-4d2c-f093-c94a5c7f60fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Response: Mothers provide unconditional love that is carried forever.\n"
          ]
        }
      ],
      "source": [
        "# from huggingface_hub import InferenceClient\n",
        "\n",
        "# def answer_question(final_context, query, model=\"Qwen/Qwen2-1.5B-Instruct\", max_tokens=500, api_key=\"your_api_key_here\"):\n",
        "#     \"\"\"\n",
        "#     Generates an answer for the query using the Hugging Face Inference API with the specified model.\n",
        "\n",
        "#     Args:\n",
        "#         final_context (str): The context to provide for the query.\n",
        "#         query (str): The user query.\n",
        "#         model (str): The model to use for chat completion.\n",
        "#         max_tokens (int): Maximum tokens for the output.\n",
        "#         api_key (str): Hugging Face API key.\n",
        "\n",
        "#     Returns:\n",
        "#         str: The model's response to the query.\n",
        "#     \"\"\"\n",
        "#     client = InferenceClient(api_key=api_key)\n",
        "#     messages = [\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": (\n",
        "#                 f\"Answer the question based on the provided context.\\n\\n\"\n",
        "#                 f\"Context:\\n{final_context}\\n\\n\"\n",
        "#                 f\"Question: {query}\\n\\n\"\n",
        "#                 f\"Provide a short answer in less than 5 words, in the following JSON format:\\n\"\n",
        "#                 f'{{\"short_answer\": \"<short answer in less than 5 words>\"}}'\n",
        "#             )\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     # Generate completion\n",
        "#     completion = client.chat.completions.create(\n",
        "#         model=model,\n",
        "#         messages=messages,\n",
        "#         max_tokens=max_tokens\n",
        "#     )\n",
        "\n",
        "#     # Extract and return the assistant's response\n",
        "#     return completion.choices[0].message['content']\n",
        "\n",
        "# # Example usage\n",
        "# final_context = \"\"\"\n",
        "# Every morning, as the first rays of sunlight peeked through the window, my mother had already been awake for hours, preparing breakfast for the family. I still vividly remember the image of her, wearing an old sweater, her hands swiftly moving the pan, with steam rising and reddening her cheeks. The aroma of the peanut sticky rice she used to cook lingers in my memory; even now, a similar scent instantly brings me back to my childhood home. Mother never sat down to eat with us; she would gently ask, \"Is it good?\" and then quietly continue tidying up. I grew up under her care, and with every step I take farther from home, my heart aches whenever I think of her. She doesn’t talk much, but her eyes always radiate love. The wrinkles on her face are like lines of time, telling stories of all the sacrifices and hardships she endured for our family. To me, she is not only the one who gave me life but also the sky full of love and gratitude that I carry forever in my heart.\n",
        "# \"\"\"\n",
        "# query = \"Can you summarize the significance of the mother's role in this passage?\"\n",
        "# response = answer_question(final_context, query, api_key=\"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\")\n",
        "# print(f\"Model Response: {response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgfFNJhssL89"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the pipeline globally for efficiency\n",
        "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", device=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnSr6XZ8sBsD",
        "outputId": "b04646ff-3a64-47c7-ce5e-4702dd6993c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Invalid JSON response received: Answer the question based on the provided context.\n",
            "\n",
            "Context:\n",
            "Miller v. California, 413 U.S. 15 (1973), was a landmark decision redefining obscenity. The Gates v. Collier case brought an end to the 'trusty system'.\n",
            "\n",
            "Question: Which case was brought to court first?\n",
            "\n",
            "Provide a short answer in less than 5 words, strictly in the following JSON format:\n",
            "{\"short_answer\": \"<short answer in less than 5 words>\"} Based on the given information, the Gates v. Collier case was brought to court first. \n",
            "\n",
            "{\"short_answer\": \"Gates v. Collier\"}\n",
            "Short Answer: \n"
          ]
        }
      ],
      "source": [
        "# from transformers import pipeline\n",
        "\n",
        "# # Initialize the pipeline globally for efficiency\n",
        "# pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2-1.5B-Instruct\", device=0)\n",
        "import json\n",
        "\n",
        "def answer_question(final_context, query):\n",
        "    \"\"\"\n",
        "    Generates an answer for the query using the Hugging Face pipeline.\n",
        "\n",
        "    Args:\n",
        "        final_context (str): The context to provide for the query.\n",
        "        query (str): The user query.\n",
        "\n",
        "    Returns:\n",
        "        str: The extracted short answer.\n",
        "    \"\"\"\n",
        "    # Construct the prompt\n",
        "    prompt = (\n",
        "        f\"Answer the question based on the provided context.\\n\\n\"\n",
        "        f\"Context:\\n{final_context}\\n\\n\"\n",
        "        f\"Question: {query}\\n\\n\"\n",
        "        f\"Provide a short answer in less than 5 words, strictly in the following JSON format:\\n\"\n",
        "        f'{{\"short_answer\": \"<short answer in less than 5 words>\"}}'\n",
        "    )\n",
        "\n",
        "    # Generate response\n",
        "    outputs = pipe(prompt, max_new_tokens=128, do_sample=False)\n",
        "    response = outputs[0][\"generated_text\"].strip()\n",
        "\n",
        "    # Try parsing as JSON\n",
        "    try:\n",
        "        response_json = json.loads(response)\n",
        "        return response_json.get(\"short_answer\", \"No answer provided\")\n",
        "    except json.JSONDecodeError:\n",
        "        # Fallback: Extract the likely answer from raw text\n",
        "        print(f\"Warning: Invalid JSON response received: {response}\")\n",
        "        if \"short_answer\" in response:\n",
        "            # Extract text between the JSON-like delimiters\n",
        "            start_idx = response.find('\"short_answer\":') + len('\"short_answer\":') + 1\n",
        "            end_idx = response.find('\"', start_idx)\n",
        "            return response[start_idx:end_idx].strip()\n",
        "        return \"Invalid JSON response\"\n",
        "\n",
        "\n",
        "\n",
        "# Example context and query\n",
        "final_context = (\n",
        "    \"Miller v. California, 413 U.S. 15 (1973), was a landmark decision redefining obscenity. \"\n",
        "    \"The Gates v. Collier case brought an end to the 'trusty system'.\"\n",
        ")\n",
        "query = \"Which case was brought to court first?\"\n",
        "\n",
        "# Generate the answer\n",
        "short_answer = answer_question(final_context, query)\n",
        "print(f\"Short Answer: {short_answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01rxIEI4sFX3"
      },
      "outputs": [],
      "source": [
        "# Example context and query\n",
        "final_context = (\n",
        "    \"Miller v. California, 413 U.S. 15 (1973), was a landmark decision redefining obscenity. \"\n",
        "    \"The Gates v. Collier case brought an end to the 'trusty system'.\"\n",
        ")\n",
        "query = \"Which case was brought to court first?\"\n",
        "\n",
        "# Generate the answer\n",
        "short_answer = answer_question(final_context, query)\n",
        "print(f\"Short Answer: {short_answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AkmZAnT8f7pX"
      },
      "outputs": [],
      "source": [
        "# # Step 2: Answer the query using the combined context\n",
        "# answer = answer_question(retrieval_final_context, query)\n",
        "query = \"What is the significance of Miller v. California?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "hkzcr3EAIMYh",
        "outputId": "d65068b9-d492-4289-8fef-8f461e10aeb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Extract the most relevant information from the following passage based on the query.\\n\\nPassage: Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of \\'utterly without socially redeeming value\\' to that which lacks \\'serious literary, artistic, political, or scientific value.\\'\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\n\\nThe answer is: Miller v. California was brought to court first. \\n\\nExplanation: The passage states that \"Miller v. California, 413 U.S. 15 (1973)\" was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of \\'utterly without socially redeeming value\\' to that which lacks\\'serious literary, artistic, political, or scientific value.\\' This indicates that Miller v. California was the case that was brought to court first. The second part of the question asks about another case, but there is no mention of any\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: The case redefined obscenity to include only materials that lack serious literary, artistic, political, or scientific value, creating the \\'Miller test\\' that is still used today.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\nThe answer: Miller v. California\\n\\nExplanation: The passage states that the case that defined obscenity as only containing materials lacking serious literary, artistic, political, or scientific value created the \"Miller test\" which is still used today. This indicates that the case that brought this definition to court was Miller v. California. Therefore, the correct answer is Miller v. California. \\n\\nGates v. Collier is not mentioned in the passage and does not provide any relevant information about the case that brought the definition of obscenity to court. Hence, it cannot be considered as a valid answer.\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: Miller appealed his conviction on the grounds that the jury had not been instructed to consider whether the material in question lacked serious value, which led to the new definition being adopted.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\nThe answer is: Miller v. California\\n\\nExplanation: The passage mentions that Miller appealed his conviction on the grounds that the jury had not been instructed to consider whether the material in question lacked serious value, which led to the new definition being adopted. This indicates that Miller\\'s appeal was related to a case where the jury did not consider the lack of serious value as an important factor. Therefore, the case that was brought to court first is Miller v. California. \\n\\nGates v. Collier is not mentioned in the passage and does not provide any information about the relevance of the jury instruction in Miller\\'s case.\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: Gates v. Collier, on the other hand, was a landmark decision by the Fifth Circuit Court of Appeals that brought an end to the \\'trusty system\\' and cruel practices at Parchman Farm prison in Mississippi.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Gates v. Collier\\nThe answer is: Gates v. Collier\\n\\nThe passage states that \"Gates v. Collier\" was a landmark decision by the Fifth Circuit Court of Appeals that brought an end to the \\'trusty system\\' and cruel practices at Parchman Farm prison in Mississippi. Therefore, it can be inferred that \"Gates v. Collier\" was brought to court first. The question asks for which case was brought to court first, and the relevant content provided in the passage confirms this. \\n\\nMiller v. California is not mentioned in the passage as being related to the context of the Fifth Circuit Court\\nExtract the most relevant information from the following passage based on the query.\\n\\nPassage: The \\'Miller test\\' consists of three prongs: whether the average person, applying contemporary community standards, would find the work appeals to the prurient interest; whether it depicts sexual conduct in a patently offensive way; and whether it lacks serious value.\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\nThe Miller test is used to determine if material is obscene under state law.\\nGates v. Collier\\nThis case involved a challenge to a state obscenity statute.\\nAnswer:\\n\\nMiller v. California was brought to court first. \\n\\nExplanation:\\n- The question asks for the order in which cases were brought to court. \\n- The passage states that \"the Miller test is used to determine if material is obscene under state law.\" This implies that the Miller test was developed before any other similar tests like the one used in Gates v. Collier.\\n- Therefore, Miller v. California was brought to court first.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_final_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goFimsklMlQo",
        "outputId": "120f833e-af27-41a3-d579-d0a6a31e97f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Response: Mothers significant in shaping their children's lives.\n"
          ]
        }
      ],
      "source": [
        "response = answer_question(retrieval_final_context, query, api_key=\"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\")\n",
        "print(f\"Model Response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m4yqz8Bhzws"
      },
      "source": [
        "model_name = \"meta-llama/Llama-3.2-1B\" # bị lỗi lặp từ trong response\n",
        "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
        "\n",
        "Output: Llama 3 1 B:\n",
        "- Extract the most relevant information from the following passage based on the query.\\n\\nPassage: Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of 'utterly without socially redeeming value' to that which lacks 'serious literary, artistic, political, or scientific value.'\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to\n",
        "1\n",
        "\n",
        "- Model Response: Miller v. California was a landmark Supreme Court case that set new legal standards for determining what constitutes a \"presumptively obscene\" work of expression. It ruled that the Court's previous decisionsLimitations.\n",
        "\n",
        "\n",
        "Output: Qwen 2 1.5B\n",
        "- Extract the most relevant information from the following passage based on the query.\\n\\nPassage: Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of \\'utterly without socially redeeming value\\' to that which lacks \\'serious literary, artistic, political, or scientific value.\\'\\n\\nQuery: Which case was brought to court first Miller v. California or Gates v. Collier \\n Relevant Content: Miller v. California\\n\\nThe answer is: Miller v. California was brought to court first. \\n\\nExplanation: The passage states that \"Miller v. California, 413 U.S. 15 (1973)\" was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of \\'utterly without socially redeeming value\\' to that which lacks\\'serious literary, artistic, political, or scientific value.\\' This indicates that Miller v. California was the case that was brought to court first. The second part of the question a\n",
        "1\n",
        "\n",
        "- Model Response: Modifies the definition of obscenity from \"absolutely without merit,\" to \"holding little to no value.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBY9bIavkhm-"
      },
      "source": [
        "### **Evaluation of Model Outputs**\n",
        "\n",
        "Here is a detailed evaluation of the outputs from **Llama 3.2-1B** and **Qwen 2.1.5B-Instruct** for the query:  \n",
        "**\"Which case was brought to court first, Miller v. California or Gates v. Collier?\"**\n",
        "\n",
        "---\n",
        "\n",
        "### **Output: Llama 3.2-1B**\n",
        "#### **Generated Output:**\n",
        "```plaintext\n",
        "Extract the most relevant information from the following passage based on the query.\n",
        "\n",
        "Passage: Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of 'utterly without socially redeeming value' to that which lacks 'serious literary, artistic, political, or scientific value.'\n",
        "\n",
        "Query: Which case was brought to court first, Miller v. California or Gates v. Collier?\n",
        "Relevant Content: Miller v. California was brought to court first. Miller v. California was brought to court first. Miller v. California was brought to court first. (repeated multiple times)\n",
        "```\n",
        "\n",
        "#### **Evaluation:**\n",
        "1. **Relevance**:\n",
        "   - The model correctly identifies **Miller v. California** as the first case.\n",
        "   - However, the relevance is overshadowed by the repeated responses.\n",
        "   - **Score: 3/5** (Correct answer but repetitive.)\n",
        "\n",
        "2. **Accuracy**:\n",
        "   - The model accurately identifies that **Miller v. California** was brought to court first in 1973.\n",
        "   - **Score: 5/5**\n",
        "\n",
        "3. **Conciseness**:\n",
        "   - The output is excessively verbose due to repeated sentences.\n",
        "   - **Score: 1/5**\n",
        "\n",
        "4. **Completeness**:\n",
        "   - While it identifies the correct case, it does not provide a clear explanation or context for the timeline.\n",
        "   - **Score: 2/5**\n",
        "\n",
        "5. **Language Quality**:\n",
        "   - The language itself is grammatically correct, but the repeated phrasing detracts from readability.\n",
        "   - **Score: 3/5**\n",
        "\n",
        "---\n",
        "\n",
        "### **Output: Qwen 2.1.5B-Instruct**\n",
        "#### **Generated Output:**\n",
        "```plaintext\n",
        "Extract the most relevant information from the following passage based on the query.\n",
        "\n",
        "Passage: Miller v. California, 413 U.S. 15 (1973), was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity from that of 'utterly without socially redeeming value' to that which lacks 'serious literary, artistic, political, or scientific value.'\n",
        "\n",
        "Query: Which case was brought to court first, Miller v. California or Gates v. Collier?\n",
        "Relevant Content: Miller v. California\n",
        "\n",
        "The answer is: Miller v. California was brought to court first.\n",
        "\n",
        "Explanation: The passage states that \"Miller v. California, 413 U.S. 15 (1973)\" was a landmark decision of the U.S. Supreme Court modifying its definition of obscenity. This indicates that Miller v. California was the case that was brought to court first.\n",
        "```\n",
        "\n",
        "#### **Evaluation:**\n",
        "1. **Relevance**:\n",
        "   - The response directly addresses the query and identifies **Miller v. California** as the first case.\n",
        "   - **Score: 5/5**\n",
        "\n",
        "2. **Accuracy**:\n",
        "   - The output accurately states the correct timeline, referencing **Miller v. California, 413 U.S. 15 (1973)**.\n",
        "   - **Score: 5/5**\n",
        "\n",
        "3. **Conciseness**:\n",
        "   - The model provides both a concise answer and a detailed explanation. However, the explanation could be slightly more succinct.\n",
        "   - **Score: 4/5**\n",
        "\n",
        "4. **Completeness**:\n",
        "   - The output includes the correct answer and relevant context, making it complete.\n",
        "   - **Score: 5/5**\n",
        "\n",
        "5. **Language Quality**:\n",
        "   - The response is grammatically correct, well-structured, and easy to read.\n",
        "   - **Score: 5/5**\n",
        "\n",
        "---\n",
        "\n",
        "### **Output Comparison**\n",
        "\n",
        "| **Criteria**      | **Llama 3.2-1B**      | **Qwen 2.1.5B-Instruct** |\n",
        "|--------------------|-----------------------|--------------------------|\n",
        "| **Relevance**      | 3/5                  | 5/5                      |\n",
        "| **Accuracy**       | 5/5                  | 5/5                      |\n",
        "| **Conciseness**    | 1/5                  | 4/5                      |\n",
        "| **Completeness**   | 2/5                  | 5/5                      |\n",
        "| **Language Quality** | 3/5                | 5/5                      |\n",
        "| **Overall Score**  | **2.8/5**            | **4.8/5**                |\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "- **Llama 3.2-1B**:\n",
        "  - While accurate, the model struggles with repeated phrases, making the output verbose and less useful.\n",
        "  - Improvement: Implement repetition penalties or refine the prompt to enforce unique answers.\n",
        "\n",
        "- **Qwen 2.1.5B-Instruct**:\n",
        "  - The model provides an accurate, concise, and well-structured response.\n",
        "  - The explanation adds context to the answer, making it more complete and user-friendly.\n",
        "\n",
        "**Winner**: **Qwen 2.1.5B-Instruct** provides a significantly better response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Làm 1 hàm xử lý file để từ file JSON ra được đến bước \n",
        "\n",
        "- lặp lại từng query của file json: \n",
        "\n",
        "query\n",
        "top_k_chunks (toàn bộ các top 20 trong file ) \n",
        "top_k=5 \n",
        "\n",
        "truyền vào \n",
        "\n",
        "retrieval_final_context = combine_top_k_chunk_text(query, top_k_chunks, top_k=5)\n",
        "\n",
        "# Step 2: Answer the query using the combined context\n",
        "response = answer_question(retrieval_final_context, query, api_key=\"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\")\n",
        "\n",
        "print(f\"Model Response: {response}\")\n",
        "\n",
        "\n",
        "để lưu lại json\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Extract short_answer from the model response\n",
        "def extract_short_answer(response):\n",
        "    \"\"\"\n",
        "    Extracts the 'short_answer' field from the model's JSON response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Parse the response string as JSON\n",
        "        response_json = json.loads(response)\n",
        "        return response_json.get(\"short_answer\", \"No answer provided\")\n",
        "    except json.JSONDecodeError:\n",
        "        return \"Invalid JSON response\"\n",
        "\n",
        "# Example usage\n",
        "response = '{\"short_answer\": \"Miller v. California\"}'\n",
        "short_answer = extract_short_answer(response)\n",
        "\n",
        "print(f\"Extracted Short Answer: {short_answer}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main processing function\n",
        "\n",
        "# Function to fetch text by chunk index\n",
        "def fetch_chunk_text(index, meta_data):\n",
        "    try:\n",
        "        return meta_data[index]['text']\n",
        "    except IndexError:\n",
        "        return \"Chunk not found.\"\n",
        "        \n",
        "def process_file_to_json(file_path_top20, file_path_meta, output_file, api_key, top_k=5):\n",
        "    \"\"\"\n",
        "    Processes the JSON file to extract queries, generate responses, and save to output JSON.\n",
        "    \"\"\"\n",
        "    with open(file_path_top20, 'r', encoding='utf-8') as file:\n",
        "        LLM_chunk_200token_Vector_search_top20 = json.load(file)\n",
        "\n",
        "    with open(file_path_meta, 'r', encoding='utf-8') as file:\n",
        "        chunks_data_meta_200token = json.load(file)\n",
        "\n",
        "    ans_predict_vector = []\n",
        "    num_queries = len(LLM_chunk_200token_Vector_search_top20)\n",
        "\n",
        "    for ind in range(num_queries):\n",
        "        torch.cuda.empty_cache()  # Clear GPU memory\n",
        "\n",
        "        # Get the query\n",
        "        query = LLM_chunk_200token_Vector_search_top20[ind]['query']\n",
        "        print(f\"Processing Query {ind}: {query}\")\n",
        "\n",
        "        # Get top-k chunks\n",
        "        top_k_chunks = []\n",
        "        for i in range(top_k):\n",
        "            index_chunk = LLM_chunk_200token_Vector_search_top20[ind]['top_20_chunk'][i]['index_chunk']\n",
        "            chunk_text = fetch_chunk_text(index_chunk, chunks_data_meta_200token)\n",
        "            top_k_chunks.append({\"text\": chunk_text})\n",
        "\n",
        "        # Generate the combined context\n",
        "        retrieval_final_context = combine_top_k_chunk_text(query, top_k_chunks, top_k=top_k)\n",
        "\n",
        "        # Generate the answer using the API\n",
        "        response = answer_question(retrieval_final_context, query, api_key=api_key)\n",
        "        response = extract_short_answer(response)\n",
        "        \n",
        "        # Append the result\n",
        "        print(f\"Short Answer: {response}\")\n",
        "        ans_predict_vector.append(response)\n",
        "        print(f\"Completed Query {ind}\")\n",
        "\n",
        "    # Write results to a JSON file\n",
        "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "        json.dump(ans_predict_vector, outfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Saved answers to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "file_path_top20 = '/kaggle/input/chunks-meta-200token/LLM_chunk_200token_Vector_search_top20.json'\n",
        "file_path_meta = '/kaggle/input/chunks-meta-200token/chunks_data_meta_200token.json'\n",
        "output_file = '/kaggle/working/Ans_LLM_200_vector_top5.json'\n",
        "api_key = \"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\"\n",
        "\n",
        "process_file_to_json(file_path_top20, file_path_meta, output_file, api_key, top_k=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
