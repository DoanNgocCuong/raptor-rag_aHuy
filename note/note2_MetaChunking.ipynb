{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong tài liệu, **Similarity Chunking** sử dụng mô hình embedding đã được huấn luyện trước để tính toán độ tương đồng giữa các câu (cosine similarity) và phân đoạn văn bản dựa trên ngưỡng độ tương đồng. Cụ thể, trong trường hợp tài liệu này, mô hình được sử dụng để thực hiện Similarity Chunking bao gồm **bge-large-en-v1.5** (cho tiếng Anh) và **bge-base-zh-v1.5** (cho tiếng Trung). Đây là các mô hình embedding dựa trên sentence embedding, được thiết kế để so sánh các câu với nhau nhằm đảm bảo rằng những câu có liên quan ngữ nghĩa được nhóm lại với nhau.\n",
    "\n",
    "Nếu bạn cần thêm thông tin hoặc phân tích sâu hơn, hãy cho tôi biết!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ví dụ MSP Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây là ví dụ minh họa về cách **MSP Chunking** hoạt động với một đoạn văn bản:\n",
    "\n",
    "---\n",
    "\n",
    "### **Đoạn văn cần phân đoạn:**\n",
    "*\"Climate change has become one of the most pressing issues of our time. It affects ecosystems, biodiversity, and human livelihoods. For instance, rising temperatures lead to the melting of polar ice caps, causing sea levels to rise and threatening coastal cities. On the other hand, it also disrupts weather patterns, leading to more frequent and severe storms.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **Quy trình phân đoạn với MSP Chunking:**\n",
    "\n",
    "1. **Cắt đoạn thành câu (hoặc tập hợp câu):**\n",
    "   - Câu 1: *\"Climate change has become one of the most pressing issues of our time.\"*\n",
    "   - Câu 2: *\"It affects ecosystems, biodiversity, and human livelihoods.\"*\n",
    "   - Câu 3: *\"For instance, rising temperatures lead to the melting of polar ice caps, causing sea levels to rise and threatening coastal cities.\"*\n",
    "   - Câu 4: *\"On the other hand, it also disrupts weather patterns, leading to more frequent and severe storms.\"*\n",
    "\n",
    "2. **Xác định từng điểm phân đoạn giữa các câu:**\n",
    "   - MSP Chunking so sánh hai lựa chọn:\n",
    "     - **Lựa chọn 1:** Kết hợp Câu 1 và Câu 2 thành một đoạn.\n",
    "     - **Lựa chọn 2:** Tách Câu 1 và Câu 2 thành hai đoạn riêng biệt.\n",
    "   - Tương tự, hệ thống sẽ thực hiện so sánh cho:\n",
    "     - Giữa Câu 2 và Câu 3.\n",
    "     - Giữa Câu 3 và Câu 4.\n",
    "\n",
    "3. **Tính toán sự khác biệt xác suất (Margin Sampling):**\n",
    "   Ví dụ:\n",
    "   - Đối với Câu 1 và Câu 2:\n",
    "     \\[\n",
    "     \\text{Margin}(C1, C2) = P(\\text{\"Split\"}) - P(\\text{\"Do not Split\"})\n",
    "     \\]\n",
    "     Nếu \\( \\text{Margin} > \\theta \\) (ngưỡng), thì Câu 1 và Câu 2 sẽ bị tách. Nếu không, chúng sẽ được giữ chung một đoạn.\n",
    "\n",
    "   Kết quả xác suất có thể là:\n",
    "   - \\( P(\\text{\"Split\"}) = 0.65 \\)\n",
    "   - \\( P(\\text{\"Do not Split\"}) = 0.25 \\)\n",
    "   - \\(\\text{Margin} = 0.65 - 0.25 = 0.4 \\).\n",
    "\n",
    "   Nếu ngưỡng \\( \\theta = 0.3 \\), thì Câu 1 và Câu 2 sẽ **được tách**.\n",
    "\n",
    "4. **Kết quả phân đoạn sau MSP Chunking:**\n",
    "   - **Đoạn 1:** *\"Climate change has become one of the most pressing issues of our time.\"*\n",
    "   - **Đoạn 2:** *\"It affects ecosystems, biodiversity, and human livelihoods.\"*\n",
    "   - **Đoạn 3:** *\"For instance, rising temperatures lead to the melting of polar ice caps, causing sea levels to rise and threatening coastal cities.\"*\n",
    "   - **Đoạn 4:** *\"On the other hand, it also disrupts weather patterns, leading to more frequent and severe storms.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **So sánh với Similarity Chunking:**\n",
    "- **Similarity Chunking** có thể giữ *Câu 1 + Câu 2* và *Câu 3 + Câu 4* chung một đoạn vì độ tương đồng ngữ nghĩa cao.\n",
    "- **Kết quả:** Similarity Chunking có thể tạo ra ít đoạn hơn nhưng có tính ngữ nghĩa sâu sắc hơn, đặc biệt phù hợp với các tác vụ cần hiểu bối cảnh tổng thể.\n",
    "\n",
    "---\n",
    "\n",
    "Nếu bạn cần thêm ví dụ hoặc phân tích sâu hơn, hãy cho tôi biết!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sao kết quả thấp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng **all-mpnet-base-v2** cho **Semantic Chunking** có thể mang lại hiệu quả tốt hơn so với **MSP Chunking** với Qwen 1.5B vì một số lý do cụ thể sau:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Chất lượng của mô hình Sentence Embedding**\n",
    "- **all-mpnet-base-v2** là một mô hình sentence embedding mạnh mẽ, được huấn luyện để **nắm bắt ý nghĩa ngữ cảnh sâu sắc giữa các câu**. \n",
    "  - Nó sử dụng kiến trúc MPNet, một cải tiến của BERT và Transformer, để kết hợp cả thông tin cục bộ và toàn cục của các câu trong văn bản.\n",
    "  - Khi thực hiện Semantic Chunking, nó tính toán độ tương đồng ngữ nghĩa giữa các câu và nhóm những câu có liên kết ngữ nghĩa vào cùng một đoạn.\n",
    "\n",
    "- **Qwen 1.5B trong MSP Chunking** không dựa vào embedding ngữ nghĩa mà sử dụng **xác suất dự đoán cục bộ** giữa các lựa chọn (tách hoặc không tách). Điều này giới hạn khả năng nắm bắt ngữ nghĩa sâu xa và toàn diện của văn bản, dẫn đến việc phân đoạn ít chính xác hơn trong các ngữ cảnh phức tạp.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Phương pháp luận của Semantic Chunking và MSP Chunking**\n",
    "#### **Semantic Chunking (all-mpnet-base-v2):**\n",
    "- Dựa trên **cosine similarity** giữa vector embedding của các câu để đánh giá mức độ liên kết ngữ nghĩa.\n",
    "- Cách tiếp cận này đảm bảo rằng các câu trong một đoạn có ý nghĩa logic chặt chẽ, ngay cả khi các câu không liền kề về mặt cấu trúc.\n",
    "\n",
    "#### **MSP Chunking (Qwen 1.5B):**\n",
    "- Dựa trên sự khác biệt xác suất giữa hai lựa chọn (\"Split\" hoặc \"Do not Split\").\n",
    "- Phương pháp này chỉ sử dụng thông tin cục bộ tại các điểm ngắt, không tận dụng ngữ nghĩa tổng thể hoặc các mối quan hệ logic sâu rộng giữa các câu.\n",
    "\n",
    "=> Semantic Chunking vượt trội hơn vì nó khai thác **ngữ nghĩa toàn cảnh** của văn bản thay vì chỉ phân đoạn dựa trên quyết định cục bộ.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Khả năng tổng quát hóa và tính linh hoạt**\n",
    "- **all-mpnet-base-v2**:\n",
    "  - Được huấn luyện trên nhiều tập dữ liệu ngôn ngữ lớn và đa dạng, giúp nó có khả năng nắm bắt nhiều loại ngữ cảnh và mối quan hệ ngữ nghĩa khác nhau.\n",
    "  - Phù hợp với cả văn bản phức tạp, dài hoặc có cấu trúc lỏng lẻo.\n",
    "\n",
    "- **Qwen 1.5B (MSP Chunking)**:\n",
    "  - Là một mô hình ngôn ngữ nhỏ hơn với mục tiêu tối ưu hóa chi phí tính toán. Điều này giới hạn khả năng xử lý ngữ nghĩa sâu rộng, đặc biệt là trong các tác vụ yêu cầu logic và sự liên kết ngữ nghĩa chặt chẽ.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Tính chính xác và độ phức tạp**\n",
    "- **Semantic Chunking**:\n",
    "  - Có chi phí tính toán cao hơn (thời gian xử lý lâu hơn), nhưng đạt được kết quả phân đoạn chính xác và hợp ngữ nghĩa hơn.\n",
    "  - Ví dụ: Trong bảng kết quả, Similarity Chunking với all-mpnet-base-v2 mất 416.45 giây nhưng đạt F1 = 12.00.\n",
    "\n",
    "- **MSP Chunking**:\n",
    "  - Tối ưu hóa để xử lý nhanh hơn (thời gian xử lý 190.93 giây với Qwen 1.5B), nhưng đánh đổi về chất lượng phân đoạn, dẫn đến điểm F1 thấp hơn (11.30).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Điểm mạnh của từng phương pháp**\n",
    "- **Semantic Chunking với all-mpnet-base-v2**:\n",
    "  - Mạnh về việc giữ nguyên ngữ cảnh và tạo ra các đoạn có ý nghĩa chặt chẽ, đặc biệt phù hợp với các tác vụ như trả lời câu hỏi (QA).\n",
    "  \n",
    "- **MSP Chunking với Qwen 1.5B**:\n",
    "  - Mạnh về hiệu quả tính toán và dễ áp dụng cho các hệ thống hạn chế tài nguyên.\n",
    "  - Tuy nhiên, nó không được tối ưu hóa cho các ngữ cảnh yêu cầu mức độ hiểu biết ngữ nghĩa cao.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tóm lại:**\n",
    "- **all-mpnet-base-v2** trong Semantic Chunking vượt trội hơn **Qwen 1.5B trong MSP Chunking** vì:\n",
    "  1. Khai thác ngữ nghĩa toàn cảnh thông qua sentence embedding.\n",
    "  2. Phù hợp hơn với các tác vụ đòi hỏi ngữ nghĩa sâu sắc và liên kết logic, đặc biệt là QA.\n",
    "  3. MSP Chunking chỉ dựa vào xác suất cục bộ, không tận dụng ngữ cảnh rộng và ngữ nghĩa sâu.\n",
    "\n",
    "Nếu cần thêm ví dụ minh họa hoặc phân tích chi tiết, hãy cho tôi biết!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pèlecxtity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ giải thích thêm tại sao thuật toán chọn **sau Câu 1 và Câu 3** để ngắt đoạn và đưa ra ví dụ dài hơn để làm rõ cách hoạt động của **Perplexity Chunking**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tại sao chọn sau Câu 1 và Câu 3?**\n",
    "1. **Nguyên tắc chính của thuật toán:**\n",
    "   - Thuật toán chọn những câu có **Perplexity thấp nhất (minima)** để làm điểm ngắt. Đây thường là những câu **dễ hiểu hơn câu trước và câu sau**, vì chúng thường đại diện cho những ý chính hoặc điểm quan trọng.\n",
    "\n",
    "2. **Câu 1 và Câu 4 trong ví dụ:**\n",
    "   - Câu 1: Là câu mở đầu, cung cấp thông tin cơ bản, nên dễ hiểu nhất (Perplexity thấp).\n",
    "   - Câu 4: Là câu kết luận, thường tổng hợp lại ý, nên cũng dễ hiểu (Perplexity thấp).\n",
    "   - Câu 3: Dài và chứa nhiều thông tin phức tạp, nên thường có **Perplexity cao hơn**.\n",
    "\n",
    "3. **Ngắt đoạn sau Câu 1 và Câu 3:**\n",
    "   - Ngắt sau Câu 1: Chia đoạn thành phần giới thiệu (Câu 1) và thông tin bổ sung (Câu 2, Câu 3).\n",
    "   - Ngắt sau Câu 3: Chia phần thông tin chi tiết và kết luận (Câu 4).\n",
    "\n",
    "---\n",
    "\n",
    "### **Ví dụ dài hơn**\n",
    "Giả sử có đoạn văn sau:\n",
    "\n",
    "*\"Cây xanh đóng vai trò rất quan trọng trong cuộc sống của chúng ta. Chúng giúp cung cấp oxy, hấp thụ khí CO2, và điều hòa không khí. Ngoài ra, cây xanh còn cung cấp bóng mát và làm giảm nhiệt độ môi trường xung quanh. Ở các thành phố lớn, cây xanh giúp giảm ô nhiễm không khí và mang lại không gian thư giãn cho con người. Tuy nhiên, hiện nay, nạn phá rừng và đô thị hóa đang làm giảm diện tích cây xanh. Điều này dẫn đến những hậu quả nghiêm trọng như biến đổi khí hậu, thiên tai, và giảm đa dạng sinh học.\"*\n",
    "\n",
    "#### **Bước 1: Chia đoạn văn thành các câu**\n",
    "- Câu 1: *\"Cây xanh đóng vai trò rất quan trọng trong cuộc sống của chúng ta.\"*\n",
    "- Câu 2: *\"Chúng giúp cung cấp oxy, hấp thụ khí CO2, và điều hòa không khí.\"*\n",
    "- Câu 3: *\"Ngoài ra, cây xanh còn cung cấp bóng mát và làm giảm nhiệt độ môi trường xung quanh.\"*\n",
    "- Câu 4: *\"Ở các thành phố lớn, cây xanh giúp giảm ô nhiễm không khí và mang lại không gian thư giãn cho con người.\"*\n",
    "- Câu 5: *\"Tuy nhiên, hiện nay, nạn phá rừng và đô thị hóa đang làm giảm diện tích cây xanh.\"*\n",
    "- Câu 6: *\"Điều này dẫn đến những hậu quả nghiêm trọng như biến đổi khí hậu, thiên tai, và giảm đa dạng sinh học.\"*\n",
    "\n",
    "---\n",
    "\n",
    "#### **Bước 2: Tính perplexity cho từng câu**\n",
    "- **Câu 1:** Perplexity thấp → Đây là câu mở đầu, dễ hiểu, giới thiệu chủ đề.\n",
    "- **Câu 2:** Perplexity trung bình → Nói về lợi ích chính của cây xanh.\n",
    "- **Câu 3:** Perplexity cao hơn → Mô tả chi tiết một lợi ích khác (giảm nhiệt độ).\n",
    "- **Câu 4:** Perplexity thấp hơn Câu 3 → Kết nối thông tin về thành phố lớn, hơi dễ hiểu hơn.\n",
    "- **Câu 5:** Perplexity cao → Chuyển sang chủ đề khác (tác hại của phá rừng), đoạn quan trọng.\n",
    "- **Câu 6:** Perplexity thấp → Kết luận, tóm gọn vấn đề.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Bước 3: Ngắt đoạn dựa trên perplexity**\n",
    "- Thuật toán tìm các điểm có **Perplexity thấp nhất** hoặc giảm đột ngột:\n",
    "  - Ngắt sau **Câu 1**: Chia phần giới thiệu.\n",
    "  - Ngắt sau **Câu 4**: Phần chi tiết về lợi ích của cây xanh.\n",
    "  - Ngắt sau **Câu 5**: Phần nói về tác hại của việc giảm cây xanh.\n",
    "\n",
    "#### **Kết quả phân đoạn:**\n",
    "- **Đoạn 1:** *\"Cây xanh đóng vai trò rất quan trọng trong cuộc sống của chúng ta.\"*\n",
    "- **Đoạn 2:** *\"Chúng giúp cung cấp oxy, hấp thụ khí CO2, và điều hòa không khí. Ngoài ra, cây xanh còn cung cấp bóng mát và làm giảm nhiệt độ môi trường xung quanh. Ở các thành phố lớn, cây xanh giúp giảm ô nhiễm không khí và mang lại không gian thư giãn cho con người.\"*\n",
    "- **Đoạn 3:** *\"Tuy nhiên, hiện nay, nạn phá rừng và đô thị hóa đang làm giảm diện tích cây xanh. Điều này dẫn đến những hậu quả nghiêm trọng như biến đổi khí hậu, thiên tai, và giảm đa dạng sinh học.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **Tại sao thuật toán hoạt động như vậy?**\n",
    "1. **Ngắt ở các điểm quan trọng:**\n",
    "   - Sau Câu 1: Để tách phần giới thiệu.\n",
    "   - Sau Câu 4: Tách thông tin chi tiết về lợi ích.\n",
    "   - Sau Câu 5: Tách thông tin về tác hại.\n",
    "\n",
    "2. **Duy trì tính liên kết trong mỗi đoạn:**\n",
    "   - Các câu trong mỗi đoạn có liên kết logic rõ ràng, dễ hiểu hơn.\n",
    "\n",
    "3. **Giúp đoạn văn dễ đọc và dễ xử lý:**\n",
    "   - Mỗi đoạn tập trung vào một ý cụ thể, làm cho văn bản dễ tiếp cận hơn.\n",
    "\n",
    "---\n",
    "\n",
    "Nếu bạn muốn thêm ví dụ hoặc cần giải thích sâu hơn, hãy cho tôi biết nhé!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta sẽ giải thích thêm tại sao thuật toán chọn **sau Câu 1 và Câu 3** để ngắt đoạn và đưa ra ví dụ dài hơn để làm rõ cách hoạt động của **Perplexity Chunking**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tại sao chọn sau Câu 1 và Câu 3?**\n",
    "1. **Nguyên tắc chính của thuật toán:**\n",
    "   - Thuật toán chọn những câu có **Perplexity thấp nhất (minima)** để làm điểm ngắt. Đây thường là những câu **dễ hiểu hơn câu trước và câu sau**, vì chúng thường đại diện cho những ý chính hoặc điểm quan trọng.\n",
    "\n",
    "2. **Câu 1 và Câu 4 trong ví dụ:**\n",
    "   - Câu 1: Là câu mở đầu, cung cấp thông tin cơ bản, nên dễ hiểu nhất (Perplexity thấp).\n",
    "   - Câu 4: Là câu kết luận, thường tổng hợp lại ý, nên cũng dễ hiểu (Perplexity thấp).\n",
    "   - Câu 3: Dài và chứa nhiều thông tin phức tạp, nên thường có **Perplexity cao hơn**.\n",
    "\n",
    "3. **Ngắt đoạn sau Câu 1 và Câu 3:**\n",
    "   - Ngắt sau Câu 1: Chia đoạn thành phần giới thiệu (Câu 1) và thông tin bổ sung (Câu 2, Câu 3).\n",
    "   - Ngắt sau Câu 3: Chia phần thông tin chi tiết và kết luận (Câu 4).\n",
    "\n",
    "---\n",
    "\n",
    "### **Ví dụ dài hơn**\n",
    "Giả sử có đoạn văn sau:\n",
    "\n",
    "*\"Cây xanh đóng vai trò rất quan trọng trong cuộc sống của chúng ta. Chúng giúp cung cấp oxy, hấp thụ khí CO2, và điều hòa không khí. Ngoài ra, cây xanh còn cung cấp bóng mát và làm giảm nhiệt độ môi trường xung quanh. Ở các thành phố lớn, cây xanh giúp giảm ô nhiễm không khí và mang lại không gian thư giãn cho con người. Tuy nhiên, hiện nay, nạn phá rừng và đô thị hóa đang làm giảm diện tích cây xanh. Điều này dẫn đến những hậu quả nghiêm trọng như biến đổi khí hậu, thiên tai, và giảm đa dạng sinh học.\"*\n",
    "\n",
    "#### **Bước 1: Chia đoạn văn thành các câu**\n",
    "- Câu 1: *\"Cây xanh đóng vai trò rất quan trọng trong cuộc sống của chúng ta.\"*\n",
    "- Câu 2: *\"Chúng giúp cung cấp oxy, hấp thụ khí CO2, và điều hòa không khí.\"*\n",
    "- Câu 3: *\"Ngoài ra, cây xanh còn cung cấp bóng mát và làm giảm nhiệt độ môi trường xung quanh.\"*\n",
    "- Câu 4: *\"Ở các thành phố lớn, cây xanh giúp giảm ô nhiễm không khí và mang lại không gian thư giãn cho con người.\"*\n",
    "- Câu 5: *\"Tuy nhiên, hiện nay, nạn phá rừng và đô thị hóa đang làm giảm diện tích cây xanh.\"*\n",
    "- Câu 6: *\"Điều này dẫn đến những hậu quả nghiêm trọng như biến đổi khí hậu, thiên tai, và giảm đa dạng sinh học.\"*\n",
    "\n",
    "---\n",
    "\n",
    "#### **Bước 2: Tính perplexity cho từng câu**\n",
    "- **Câu 1:** Perplexity thấp → Đây là câu mở đầu, dễ hiểu, giới thiệu chủ đề.\n",
    "- **Câu 2:** Perplexity trung bình → Nói về lợi ích chính của cây xanh.\n",
    "- **Câu 3:** Perplexity cao hơn → Mô tả chi tiết một lợi ích khác (giảm nhiệt độ).\n",
    "- **Câu 4:** Perplexity thấp hơn Câu 3 → Kết nối thông tin về thành phố lớn, hơi dễ hiểu hơn.\n",
    "- **Câu 5:** Perplexity cao → Chuyển sang chủ đề khác (tác hại của phá rừng), đoạn quan trọng.\n",
    "- **Câu 6:** Perplexity thấp → Kết luận, tóm gọn vấn đề.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Bước 3: Ngắt đoạn dựa trên perplexity**\n",
    "- Thuật toán tìm các điểm có **Perplexity thấp nhất** hoặc giảm đột ngột:\n",
    "  - Ngắt sau **Câu 1**: Chia phần giới thiệu.\n",
    "  - Ngắt sau **Câu 4**: Phần chi tiết về lợi ích của cây xanh.\n",
    "  - Ngắt sau **Câu 5**: Phần nói về tác hại của việc giảm cây xanh.\n",
    "\n",
    "#### **Kết quả phân đoạn:**\n",
    "- **Đoạn 1:** *\"Cây xanh đóng vai trò rất quan trọng trong cuộc sống của chúng ta.\"*\n",
    "- **Đoạn 2:** *\"Chúng giúp cung cấp oxy, hấp thụ khí CO2, và điều hòa không khí. Ngoài ra, cây xanh còn cung cấp bóng mát và làm giảm nhiệt độ môi trường xung quanh. Ở các thành phố lớn, cây xanh giúp giảm ô nhiễm không khí và mang lại không gian thư giãn cho con người.\"*\n",
    "- **Đoạn 3:** *\"Tuy nhiên, hiện nay, nạn phá rừng và đô thị hóa đang làm giảm diện tích cây xanh. Điều này dẫn đến những hậu quả nghiêm trọng như biến đổi khí hậu, thiên tai, và giảm đa dạng sinh học.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **Tại sao thuật toán hoạt động như vậy?**\n",
    "1. **Ngắt ở các điểm quan trọng:**\n",
    "   - Sau Câu 1: Để tách phần giới thiệu.\n",
    "   - Sau Câu 4: Tách thông tin chi tiết về lợi ích.\n",
    "   - Sau Câu 5: Tách thông tin về tác hại.\n",
    "\n",
    "2. **Duy trì tính liên kết trong mỗi đoạn:**\n",
    "   - Các câu trong mỗi đoạn có liên kết logic rõ ràng, dễ hiểu hơn.\n",
    "\n",
    "3. **Giúp đoạn văn dễ đọc và dễ xử lý:**\n",
    "   - Mỗi đoạn tập trung vào một ý cụ thể, làm cho văn bản dễ tiếp cận hơn.\n",
    "\n",
    "---\n",
    "\n",
    "Nếu bạn muốn thêm ví dụ hoặc cần giải thích sâu hơn, hãy cho tôi biết nhé!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Giải thích công thức toán học của Margin Sampling Chunking**\n",
    "\n",
    "Margin Sampling Chunking là một phương pháp dùng mô hình ngôn ngữ để quyết định điểm ngắt (segmentation points) trong văn bản. Quyết định này được dựa trên **sự khác biệt xác suất** giữa hai lựa chọn:\n",
    "1. **Gộp** câu hiện tại với câu trước đó.\n",
    "2. **Tách** câu hiện tại thành một đoạn riêng.\n",
    "\n",
    "Công thức chính:\n",
    "\\[\n",
    "\\text{Margin}_M(x_i) = P_M(y = k_1 \\mid \\text{Prompt}(x_i, X')) - P_M(y = k_2 \\mid \\text{Prompt}(x_i, X'))\n",
    "\\]\n",
    "\n",
    "#### **Giải thích từng thành phần của công thức**\n",
    "1. **\\( x_i \\):**\n",
    "   - Đây là câu hiện tại đang được xem xét trong văn bản.\n",
    "   - Ví dụ: Trong một đoạn văn, \\( x_i \\) có thể là câu thứ 2 hoặc câu thứ 3.\n",
    "\n",
    "2. **\\( P_M(y = k_1 \\mid \\text{Prompt}(x_i, X')) \\):**\n",
    "   - Đây là **xác suất** mà mô hình \\( M \\) dự đoán rằng hai câu nên **gộp chung**.\n",
    "   - \\( \\text{Prompt}(x_i, X') \\): Là yêu cầu mà mô hình nhận được để đánh giá, trong đó \\( x_i \\) là câu đang xét và \\( X' \\) là câu trước đó (hoặc một tập các câu trước đó).\n",
    "\n",
    "3. **\\( P_M(y = k_2 \\mid \\text{Prompt}(x_i, X')) \\):**\n",
    "   - Đây là **xác suất** mà mô hình \\( M \\) dự đoán rằng hai câu nên **tách ra**.\n",
    "   - Tương tự, nó cũng dựa vào \\( \\text{Prompt}(x_i, X') \\).\n",
    "\n",
    "4. **\\( \\text{Margin}_M(x_i) \\):**\n",
    "   - Là sự chênh lệch xác suất giữa hai lựa chọn (\"Gộp\" và \"Tách\"):\n",
    "     \\[\n",
    "     \\text{Margin}_M(x_i) = P_M(\\text{\"Gộp\"}) - P_M(\\text{\"Tách\"})\n",
    "     \\]\n",
    "   - Giá trị \\( \\text{Margin}_M(x_i) \\):\n",
    "     - Nếu \\( \\text{Margin}_M(x_i) > \\theta \\): Hai câu được **gộp**.\n",
    "     - Nếu \\( \\text{Margin}_M(x_i) \\leq \\theta \\): Hai câu được **tách ra**.\n",
    "\n",
    "5. **Ngưỡng \\( \\theta \\):**\n",
    "   - Đây là giá trị ngưỡng để quyết định ngắt câu. Ban đầu, \\( \\theta \\) thường được đặt bằng 0 và sau đó có thể được điều chỉnh dựa trên các giá trị trung bình của \\( \\text{Margin}_M(x_i) \\) trong dữ liệu trước đó.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Quy trình thực hiện**\n",
    "1. **Chia văn bản thành các câu nhỏ**:\n",
    "   - Ví dụ: *\"Mèo thích chơi đùa. Nó thích ăn cá. Chó thích chạy nhảy.\"*\n",
    "     - \\( x_1 = \\text{\"Mèo thích chơi đùa.\"} \\)\n",
    "     - \\( x_2 = \\text{\"Nó thích ăn cá.\"} \\)\n",
    "     - \\( x_3 = \\text{\"Chó thích chạy nhảy.\"} \\)\n",
    "\n",
    "2. **Tính xác suất \\( P_M(y = k_1) \\) và \\( P_M(y = k_2) \\):**\n",
    "   - Ví dụ:\n",
    "     - Với \\( x_2 = \\text{\"Nó thích ăn cá.\"} \\):\n",
    "       - \\( P_M(\\text{\"Gộp\"}) = 0.75 \\)\n",
    "       - \\( P_M(\\text{\"Tách\"}) = 0.25 \\)\n",
    "\n",
    "3. **Tính \\( \\text{Margin}_M(x_i) \\):**\n",
    "   - Với \\( x_2 \\):\n",
    "     \\[\n",
    "     \\text{Margin}_M(x_2) = 0.75 - 0.25 = 0.5\n",
    "     \\]\n",
    "\n",
    "4. **So sánh với ngưỡng \\( \\theta \\):**\n",
    "   - Nếu \\( \\theta = 0.4 \\):\n",
    "     - \\( \\text{Margin}_M(x_2) = 0.5 > 0.4 \\), nên \\( x_1 \\) và \\( x_2 \\) **gộp chung**.\n",
    "   - Nếu \\( \\theta = 0.6 \\):\n",
    "     - \\( \\text{Margin}_M(x_2) = 0.5 < 0.6 \\), nên \\( x_2 \\) **tách ra** thành đoạn riêng.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Ví dụ cụ thể**\n",
    "Văn bản: *\"Mèo thích chơi đùa. Nó thích ăn cá. Chó thích chạy nhảy.\"*\n",
    "- Bước 1: Chia câu:\n",
    "  - \\( x_1 = \\text{\"Mèo thích chơi đùa.\"} \\)\n",
    "  - \\( x_2 = \\text{\"Nó thích ăn cá.\"} \\)\n",
    "  - \\( x_3 = \\text{\"Chó thích chạy nhảy.\"} \\)\n",
    "\n",
    "- Bước 2: Tính xác suất:\n",
    "  - Với \\( x_2 \\): \\( P_M(\\text{\"Gộp\"}) = 0.75 \\), \\( P_M(\\text{\"Tách\"}) = 0.25 \\).\n",
    "  - Với \\( x_3 \\): \\( P_M(\\text{\"Gộp\"}) = 0.4 \\), \\( P_M(\\text{\"Tách\"}) = 0.6 \\).\n",
    "\n",
    "- Bước 3: Tính \\( \\text{Margin}_M(x_i) \\):\n",
    "  - \\( \\text{Margin}_M(x_2) = 0.75 - 0.25 = 0.5 \\).\n",
    "  - \\( \\text{Margin}_M(x_3) = 0.4 - 0.6 = -0.2 \\).\n",
    "\n",
    "- Bước 4: So sánh với \\( \\theta = 0.4 \\):\n",
    "  - \\( \\text{Margin}_M(x_2) = 0.5 > 0.4 \\): \\( x_1 \\) và \\( x_2 \\) được gộp.\n",
    "  - \\( \\text{Margin}_M(x_3) = -0.2 < 0.4 \\): \\( x_3 \\) được tách ra.\n",
    "\n",
    "- Kết quả:\n",
    "  - **Đoạn 1:** *\"Mèo thích chơi đùa. Nó thích ăn cá.\"*\n",
    "  - **Đoạn 2:** *\"Chó thích chạy nhảy.\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **Tóm tắt**\n",
    "1. **Margin Sampling Chunking** sử dụng mô hình để tính xác suất giữa hai lựa chọn gộp hoặc tách.\n",
    "2. Dựa vào sự chênh lệch xác suất (\\( \\text{Margin}_M(x_i) \\)), thuật toán quyết định có nên gộp hay tách câu.\n",
    "3. Ngưỡng \\( \\theta \\) điều chỉnh độ chính xác và mức độ ngắt đoạn phù hợp.\n",
    "\n",
    "Nếu cần thêm ví dụ hoặc giải thích chi tiết hơn, bạn hãy cho tôi biết nhé!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
